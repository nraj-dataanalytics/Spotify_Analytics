{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba5e952-2c57-4f3b-a36e-e15b99ef7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripts/02_preprocess_spotify.py\n",
    "# Purpose: Clean + standardize Spotify dataset for Power BI ingestion\n",
    "# Output: data/processed/spotify_clean.csv\n",
    "\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "RAW_PATH = os.path.join(\"data\", \"raw\", \"spotify_raw.csv\")\n",
    "OUT_PATH = os.path.join(\"data\", \"processed\", \"spotify_clean.csv\")\n",
    "\n",
    "\n",
    "def _normalize_text(x: str) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    x = str(x).strip()\n",
    "    x = unicodedata.normalize(\"NFKD\", x)\n",
    "    x = \"\".join(ch for ch in x if not unicodedata.combining(ch))\n",
    "    x = re.sub(r\"\\s+\", \" \", x)  # collapse whitespace\n",
    "    return x\n",
    "\n",
    "\n",
    "def _titlecase_artist(x: str) -> str:\n",
    "    x = _normalize_text(x)\n",
    "    # keep common stylings: ALL CAPS acronyms, & and ' etc.\n",
    "    # simple approach: title-case, then fix known patterns\n",
    "    x = x.title()\n",
    "    x = re.sub(r\"\\bDj\\b\", \"DJ\", x)\n",
    "    x = re.sub(r\"\\bRnb\\b\", \"R&B\", x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def _standardize_album_type(x: str) -> str:\n",
    "    x = _normalize_text(x).lower()\n",
    "    mapping = {\n",
    "        \"album\": \"album\",\n",
    "        \"single\": \"single\",\n",
    "        \"compilation\": \"compilation\",\n",
    "        \"ep\": \"ep\",\n",
    "    }\n",
    "    return mapping.get(x, \"other\")\n",
    "\n",
    "\n",
    "def _to_bool_explicit(x):\n",
    "    # handles True/False, 0/1, \"explicit\"/\"non-explicit\"\n",
    "    if pd.isna(x):\n",
    "        return False\n",
    "    if isinstance(x, bool):\n",
    "        return x\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"1\", \"true\", \"t\", \"yes\", \"explicit\"}:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(RAW_PATH):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing raw dataset at {RAW_PATH}. Put your CSV there as data/raw/spotify_raw.csv\"\n",
    "        )\n",
    "\n",
    "    df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "    # ---- Expected columns (adjust if your dataset uses different names) ----\n",
    "    # track_name, artist_name, album_name, album_type, release_date, duration_ms, popularity, explicit\n",
    "    col_map_candidates = {\n",
    "        \"track_name\": [\"track_name\", \"song\", \"track\", \"name\"],\n",
    "        \"artist_name\": [\"artist_name\", \"artist\", \"artists\"],\n",
    "        \"album_name\": [\"album_name\", \"album\"],\n",
    "        \"album_type\": [\"album_type\", \"type\"],\n",
    "        \"release_date\": [\"release_date\", \"released\", \"release\"],\n",
    "        \"duration_ms\": [\"duration_ms\", \"duration\", \"durationmilliseconds\"],\n",
    "        \"popularity\": [\"popularity\", \"popularity_score\", \"score\"],\n",
    "        \"explicit\": [\"explicit\", \"is_explicit\"],\n",
    "    }\n",
    "\n",
    "    # Auto-map columns if naming differs\n",
    "    lower_cols = {c.lower(): c for c in df.columns}\n",
    "    resolved = {}\n",
    "    for std, opts in col_map_candidates.items():\n",
    "        for o in opts:\n",
    "            if o.lower() in lower_cols:\n",
    "                resolved[std] = lower_cols[o.lower()]\n",
    "                break\n",
    "\n",
    "    missing = [k for k in [\"track_name\", \"artist_name\", \"release_date\", \"popularity\"] if k not in resolved]\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Missing required fields in your CSV: {missing}. \"\n",
    "            f\"Found columns: {list(df.columns)}. \"\n",
    "            f\"Edit the mapping section in this script to match your dataset.\"\n",
    "        )\n",
    "\n",
    "    # Rename to standard names\n",
    "    df = df.rename(columns={resolved[k]: k for k in resolved})\n",
    "\n",
    "    # ---- Cleaning / Standardization ----\n",
    "    df[\"track_name\"] = df[\"track_name\"].apply(_normalize_text)\n",
    "    df[\"artist_name\"] = df[\"artist_name\"].apply(_titlecase_artist)\n",
    "\n",
    "    if \"album_name\" in df.columns:\n",
    "        df[\"album_name\"] = df[\"album_name\"].apply(_normalize_text)\n",
    "\n",
    "    if \"album_type\" in df.columns:\n",
    "        df[\"album_type\"] = df[\"album_type\"].apply(_standardize_album_type)\n",
    "    else:\n",
    "        df[\"album_type\"] = \"other\"\n",
    "\n",
    "    if \"explicit\" in df.columns:\n",
    "        df[\"explicit\"] = df[\"explicit\"].apply(_to_bool_explicit)\n",
    "    else:\n",
    "        df[\"explicit\"] = False\n",
    "\n",
    "    # release_date parsing\n",
    "    df[\"release_date\"] = pd.to_datetime(df[\"release_date\"], errors=\"coerce\")\n",
    "    df = df[~df[\"release_date\"].isna()].copy()\n",
    "\n",
    "    df[\"release_year\"] = df[\"release_date\"].dt.year.astype(int)\n",
    "    df[\"release_month_num\"] = df[\"release_date\"].dt.month.astype(int)\n",
    "    df[\"release_month\"] = df[\"release_date\"].dt.strftime(\"%b\")  # Jan, Feb...\n",
    "    df[\"release_year_month\"] = df[\"release_date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "    # duration\n",
    "    if \"duration_ms\" in df.columns:\n",
    "        df[\"duration_ms\"] = pd.to_numeric(df[\"duration_ms\"], errors=\"coerce\")\n",
    "        df[\"duration_minutes\"] = (df[\"duration_ms\"] / 1000 / 60).round(2)\n",
    "    else:\n",
    "        df[\"duration_minutes\"] = pd.NA\n",
    "\n",
    "    # popularity\n",
    "    df[\"popularity\"] = pd.to_numeric(df[\"popularity\"], errors=\"coerce\")\n",
    "    df = df[~df[\"popularity\"].isna()].copy()\n",
    "\n",
    "    # Deduplicate: keep the most popular record for same artist+track+date\n",
    "    dedupe_cols = [\"artist_name\", \"track_name\", \"release_date\"]\n",
    "    df = (\n",
    "        df.sort_values([\"popularity\"], ascending=False)\n",
    "          .drop_duplicates(subset=dedupe_cols, keep=\"first\")\n",
    "          .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
    "    df.to_csv(OUT_PATH, index=False)\n",
    "\n",
    "    print(\"âœ… Clean file created:\", OUT_PATH)\n",
    "    print(\"Rows:\", len(df), \" | Columns:\", len(df.columns))\n",
    "    print(\"Artists:\", df[\"artist_name\"].nunique(), \" | Songs:\", df[\"track_name\"].nunique())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
